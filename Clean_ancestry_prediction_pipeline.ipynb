{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876b84e9-f272-4d97-acac-e44b16f81ad6",
   "metadata": {},
   "source": [
    "# Packages to load those are not there:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5137a91-e962-432c-8bac-4329cc292874",
   "metadata": {},
   "source": [
    "## Note: Don't need to run these if already ran like once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0074f-8b45-44a1-9b73-043844605c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c2d59-441c-421b-8c27-72b19c5c1753",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390a911-5191-4c43-9f8d-edcf03bd0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc6896-15e6-45e7-89b6-01ae1eb8b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626267a-f4be-41cc-9d64-3cc1d4bb189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gnomad --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a03ed-9629-4ce3-ab30-3725565fef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c0ded-d78a-4e26-a459-d86c89a118db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install skl2onnx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5149aa5-1f9b-4dcd-a4ae-cbc2ed060bdc",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364540f-417a-4326-988a-8eb9a66e3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e773bcc-189f-4e8f-bbc9-20a87ee279f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "# import os\n",
    "# import onnx\n",
    "\n",
    "# Initialize Hail with optimized Spark settings for 64 cores & 196GB RAM\n",
    "hl.init(\n",
    "    tmp_dir=\"/tmp\",\n",
    "    log=\"/tmp/hail.log\",\n",
    "    default_reference=\"GRCh38\",\n",
    "    spark_conf={\n",
    "        \"spark.executor.memory\": \"180g\",  # Use 180GB for Spark, leave ~16GB for OS\n",
    "        \"spark.driver.memory\": \"180g\",\n",
    "        \"spark.executor.cores\": \"64\",  # Utilize all 64 cores\n",
    "        \"spark.driver.cores\": \"64\",\n",
    "        \"spark.local.dir\": \"/tmp\",\n",
    "        \"spark.sql.files.maxPartitionBytes\": \"32m\",  # Efficient partitioning\n",
    "        \"spark.sql.shuffle.partitions\": \"256\",  # Increase parallel shuffle performance\n",
    "        \"spark.memory.fraction\": \"0.9\",  # Use 90% of allocated memory\n",
    "        \"spark.memory.storageFraction\": \"0.7\",  # Optimize caching\n",
    "        \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "        \"spark.dynamicAllocation.minExecutors\": \"1\",\n",
    "        \"spark.dynamicAllocation.maxExecutors\": \"64\",\n",
    "        \"spark.sql.execution.arrow.enabled\": \"true\",  # Faster DataFrame processing\n",
    "        \"spark.driver.extraJavaOptions\": \"-Dorg.slf4j.simpleLogger.defaultLogLevel=error\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4d19f-1809-4f4e-9b3c-4347b4128123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import hail as hl\n",
    "# hl.init(idempotent = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a70bcb-1feb-4e56-a659-236de1b4f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104ac36-63b9-4573-8f95-e9cc33a107fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnomad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f73903-d414-4835-a53b-ec027aa1ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnomad.sample_qc.ancestry import apply_onnx_classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02bdef-46c0-4c77-a1fd-fdffeefbd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnomad.utils.filtering import filter_to_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb2910-6ee1-4aa8-acff-1f95ec3d4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnomad.sample_qc.ancestry import assign_population_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b19ec7-82c1-4b25-8fdf-cd1a9d3048cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3.1 PCA loadings.\n",
    "gnomad_v3_loadings = \"/home/ky134/gnomad.v4.0.pca_loadings.ht/gnomad.v4.0.pca_loadings.ht\"\n",
    "\n",
    "# v3.1 ONNX RF model.\n",
    "gnomad_v3_onnx_rf = \"/home/ky134/gnomad.v4.0.RF_fit.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cedfb-4cb6-400a-b8a3-f6072f860b19",
   "metadata": {},
   "source": [
    "# Pipeline Starting for single vcf/vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0b064-f17a-4545-a519-a1f7b63b48ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the vcf\n",
    "# input_folder = \"/data/irb/pediatrics/pro00094341ncd/Sequencing (NC-DEFINE)/NC-DEFINE Manuscript SVD Prospective/\"\n",
    "\n",
    "#mt = hl.import_vcf(r\"/data/irb/pediatrics/pro00094341ncd/Sequencing_NC_DEFINE/Balint_10012_vcfs/chr1.vcf.gz\", array_elements_required=False, reference_genome = \"GRCh38\", force_bgz=True)\n",
    "mt = hl.import_vcf(r\"file.vcf.gz\", reference_genome = \"GRCh38\", force_bgz=True, array_elements_required=False)\n",
    "\n",
    "############# USE THE Uncomment out the below code for the file all which was from genomics core that we got after merging all the chr files ###############\n",
    "#mt = mt.annotate_rows(info=mt.info.drop(\"AS_QUAL\"))\n",
    "\n",
    "# Split multi-allelic sites\n",
    "#mt = hl.split_multi_hts(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99291ed-9806-4724-a7d8-6cb280704c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'info' column from the MatrixTable\n",
    "#mt = mt.drop(mt.info)\n",
    "\n",
    "# Confirm the column is removed\n",
    "mt.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f7acd-63e6-453f-a62b-dc17197e10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path for your GCS directory\n",
    "base_path = \"output/temp.anno\"\n",
    "\n",
    "# Output paths in the same directory\n",
    "test_mt_output_path = f\"{base_path}/all.anno_ancestry.mt\"\n",
    "test_scores_output_path = f\"{base_path}/all.anno_ancestry.scores.ht\"\n",
    "gnomad_v3_assignment_path = f\"{base_path}/all.anno_ancestry.assignment.ht\"\n",
    "\n",
    "# Print paths to verify\n",
    "print(\"MatrixTable Output Path:\", test_mt_output_path)\n",
    "print(\"Scores Output Path:\", test_scores_output_path)\n",
    "print(\"Assignment Output Path:\", gnomad_v3_assignment_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4df68-83e1-4433-ac79-cad9576df43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_num_pcs = 20\n",
    "v3_min_prob = 0.55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23de3f6-fad2-49b2-a92b-44edcbbf74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_loading_ht = hl.read_table(gnomad_v3_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ebaa3-6dda-432e-bcb3-69e30d8d70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with hl.hadoop_open(gnomad_v3_onnx_rf, \"rb\") as f:\n",
    "#     v3_onx_fit = onnx.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92244e-5a32-48ad-a3e1-a99c0a47b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "with open(gnomad_v3_onnx_rf, \"rb\") as f:\n",
    "    v3_onx_fit = onnx.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025a42b-13e7-4be6-a358-899980dce08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbce459-8631-4dcd-a6b9-0949e0f3a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on the v3_loading_ht table\n",
    "mt = mt.filter_rows(hl.is_defined(v3_loading_ht[mt.row_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528c9fa-db92-451b-b896-7ec1153015d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = filter_to_adj(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7ec36-abdd-4221-9df4-c182a667191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_if_exists = True\n",
    "\n",
    "# mt = mt.checkpoint(\n",
    "#     test_mt_output_path, overwrite=not _read_if_exists=read_if_exists\n",
    "# )\n",
    "\n",
    "mt = mt.checkpoint(\n",
    "    test_mt_output_path, overwrite=not read_if_exists, _read_if_exists=read_if_exists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c24879-806c-4d7c-95d5-67bb1a0a681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project new genotypes onto loadings.\n",
    "v3_pcs_ht = hl.experimental.pc_project(\n",
    "    mt.GT,\n",
    "    v3_loading_ht.loadings,\n",
    "    v3_loading_ht.pca_af,\n",
    ")\n",
    "\n",
    "# Checkpoint PC projection results.\n",
    "v3_pcs_ht = v3_pcs_ht.checkpoint(\n",
    "    test_scores_output_path,\n",
    "    overwrite=not read_if_exists,\n",
    "    _read_if_exists=read_if_exists,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215c087-a145-42da-a005-a7b09bd9016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign populations using the ONNX model with max 20 PCs\n",
    "ht, model = assign_population_pcs(\n",
    "    v3_pcs_ht,\n",
    "    pc_cols=v3_pcs_ht.scores[:v3_num_pcs],  # Restrict to at most 20 PCs\n",
    "    fit=v3_onx_fit,\n",
    "    min_prob=v3_min_prob,\n",
    "    apply_model_func=apply_onnx_classification_model,\n",
    ")\n",
    "\n",
    "ht = ht.checkpoint(\n",
    "    gnomad_v3_assignment_path,\n",
    "    overwrite=not read_if_exists,\n",
    "    _read_if_exists=read_if_exists,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7153a1-3718-4176-b482-1fb3e9ee4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ht.aggregate(hl.agg.counter(ht.pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4efc7-a883-47be-a9c5-f413b4970ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_pcs_ht.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e924c95-2e0b-43a9-a6a9-9020045ae8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_pcs_ht.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73c5d1-46b5-4acb-873f-bb150d628072",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875dd4a5-8359-4c7d-8cc3-8193d698f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.show(ht.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c704c6-97ec-4290-83b9-c2c72ff31c97",
   "metadata": {},
   "source": [
    "# CODE FOR ANCESTRY PREDICTION of multiple files in a folder:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff4ba9-ed77-478a-a4e6-e23d3bb0ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hail as hl\n",
    "# import os\n",
    "# import onnx\n",
    "\n",
    "# Initialize Hail\n",
    "#hl.init()\n",
    "\n",
    "# Paths and configurations\n",
    "input_folder = \"input_folder\"\n",
    "output_base_path = \"output_folder\"\n",
    "gnomad_v3_loadings = \"/home/gnomad.v4.0.pca_loadings.ht/gnomad.v4.0.pca_loadings.ht\"\n",
    "gnomad_v3_onnx_rf = \"/home/gnomad.v4.0.RF_fit.onnx\"\n",
    "\n",
    "v3_min_prob = 0.55\n",
    "read_if_exists = True\n",
    "\n",
    "# Load PCA loadings and ONNX model\n",
    "v3_loading_ht = hl.read_table(gnomad_v3_loadings)\n",
    "with open(gnomad_v3_onnx_rf, \"rb\") as f:\n",
    "    v3_onx_fit = onnx.load(f)\n",
    "\n",
    "# Process all VCF files in the folder\n",
    "vcf_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(\".vcf.gz\")]\n",
    "\n",
    "for vcf_file in vcf_files:\n",
    "    print(f\"Processing file: {vcf_file}\")\n",
    "    \n",
    "    # Extract the base filename (e.g., 24291D-01-10 from 24291D-01-10.anno.vcf.gz)\n",
    "    base_name = os.path.basename(vcf_file).replace(\".vcf.gz\", \"\")\n",
    "    \n",
    "    # Define output paths\n",
    "    mt_output_path = f\"{output_base_path}/{base_name}_ancestry.mt\"\n",
    "    scores_output_path = f\"{output_base_path}/{base_name}_ancestry.scores.ht\"\n",
    "    assignment_output_path = f\"{output_base_path}/{base_name}_ancestry.assignment.ht\"\n",
    "    \n",
    "    # Import the VCF file\n",
    "    mt = hl.import_vcf(vcf_file, reference_genome=\"GRCh38\", array_elements_required=False, force_bgz=True)\n",
    "    \n",
    "    # Split multi-allelic sites\n",
    "    # mt = hl.split_multi_hts(mt)\n",
    "    \n",
    "    # Filter rows based on PCA loadings table\n",
    "    mt = mt.filter_rows(hl.is_defined(v3_loading_ht[mt.row_key]))\n",
    "    \n",
    "    # Apply additional filters if needed (e.g., filter to adj genotypes)\n",
    "    mt = filter_to_adj(mt)\n",
    "    \n",
    "    # Save the processed MatrixTable\n",
    "    mt = mt.checkpoint(mt_output_path, overwrite=not read_if_exists, _read_if_exists=read_if_exists)\n",
    "    \n",
    "    # Project new genotypes onto PCA loadings\n",
    "    v3_pcs_ht = hl.experimental.pc_project(mt.GT, v3_loading_ht.loadings, v3_loading_ht.pca_af)\n",
    "    \n",
    "    # Save PC projection results\n",
    "    v3_pcs_ht = v3_pcs_ht.checkpoint(scores_output_path, overwrite=not read_if_exists, _read_if_exists=read_if_exists)\n",
    "\n",
    "    # Determine the number of available PCs but limit to 20\n",
    "    # num_pcs = min(v3_pcs_ht.aggregate(hl.agg.max(hl.len(v3_pcs_ht.scores))), 20)\n",
    "    num_pcs = 20\n",
    "    \n",
    "    # Assign populations using the ONNX model with max 20 PCs\n",
    "    ht, model = assign_population_pcs(\n",
    "        v3_pcs_ht,\n",
    "        pc_cols=v3_pcs_ht.scores[:num_pcs],  # Restrict to at most 20 PCs\n",
    "        fit=v3_onx_fit,\n",
    "        min_prob=v3_min_prob,\n",
    "        apply_model_func=apply_onnx_classification_model,\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Save the assignment results\n",
    "    ht = ht.checkpoint(assignment_output_path, overwrite=not read_if_exists, _read_if_exists=read_if_exists)\n",
    "    \n",
    "    # Display population assignment results\n",
    "    pop_counts = ht.aggregate(hl.agg.counter(ht.pop))\n",
    "    print(f\"Population assignment for {base_name}:\")\n",
    "    print(pop_counts)\n",
    "    \n",
    "    print(f\"Completed processing for: {vcf_file}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
